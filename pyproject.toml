[build-system]
requires = ["hatchling~=1.14.0", "hatch-requirements-txt >= 0.4.1, <0.5.0"]
build-backend = "hatchling.build"

[project]
name = "metricflow"
version = "0.206.0.dev3"
description = "Translates a simple metric definition into reusable SQL and executes it against the SQL engine of your choice."
readme = "README.md"
requires-python = ">=3.8,<3.13"
license = "BUSL-1.1"
keywords = []
authors = [
  {name = "dbt Labs"}
]

classifiers = [
  "Development Status :: 4 - Beta",
  "Programming Language :: Python",
  "Programming Language :: Python :: 3.8",
  "Programming Language :: Python :: 3.9",
  "Programming Language :: Python :: 3.10",
  "Programming Language :: Python :: 3.11",
  "Programming Language :: Python :: 3.12",
  "Programming Language :: Python :: Implementation :: CPython",
  "Programming Language :: Python :: Implementation :: PyPy",
]
dependencies = [
  "Jinja2>=3.1.3",
  "PyYAML>=6.0, <7.0.0",
  "dbt-semantic-interfaces>=0.5.1, <0.6.0",
  "graphviz>=0.18.2, <0.21",
  "more-itertools>=8.10.0, <10.2.0",
  "pydantic>=1.10.0, <1.11.0",
  "python-dateutil>=2.8.2, <2.9.0",
  "rapidfuzz>=3.0, <4.0",
  "tabulate>=0.8.9",
  "typing_extensions>=4.4, <5.0",
]

# Optional dependencies are specified through the `hatch-requirements-txt` plug-in.
dynamic = ["optional-dependencies"]

[project.urls]
Documentation = "https://docs.getdbt.com/docs/build/about-metricflow"
"Source Code" = "https://github.com/dbt-labs/metricflow"

[tool.hatch.metadata.hooks.requirements_txt.optional-dependencies]
dbt-bigquery = [
  "dbt-metricflow/extra-hatch-configuration/requirements-dbt-bigquery.txt"
]
dbt-databricks = [
  "dbt-metricflow/extra-hatch-configuration/requirements-dbt-databricks.txt"
]
dbt-duckdb = [
  "dbt-metricflow/extra-hatch-configuration/requirements-dbt-duckdb.txt"
]
dbt-postgres = [
  "dbt-metricflow/extra-hatch-configuration/requirements-dbt-postgres.txt"
]
dbt-redshift = [
  "dbt-metricflow/extra-hatch-configuration/requirements-dbt-redshift.txt"
]
dbt-snowflake = [
  "dbt-metricflow/extra-hatch-configuration/requirements-dbt-snowflake.txt"
]
dbt-trino = [
  "dbt-metricflow/extra-hatch-configuration/requirements-dbt-trino.txt"
]
dev-packages = [
  "extra-hatch-configuration/requirements-dev-packages.txt",
  "dbt-metricflow/extra-hatch-configuration/requirements-cli.txt"
]
sql-client-packages = [
  "extra-hatch-configuration/requirements-sql-client-packages.txt"
]
trino-sql-client-packages = [
  "extra-hatch-configuration/requirements-trino-sql-client-packages.txt"
]

# There are files that hatch will always include as well (e.g. the LICENSE file).
# See hatch build docs for more details.
[tool.hatch.build.targets.sdist]
packages = ["metricflow", "metricflow-semantics/metricflow_semantics"]

# include doesn't seem to work with packages, so using force include.
[tool.hatch.build.targets.sdist.force-include]
"ATTRIBUTION.md" = "ATTRIBUTION.md"

[tool.hatch.build.targets.wheel]
packages = ["metricflow", "metricflow-semantics/metricflow_semantics"]

[tool.hatch.build.targets.wheel.force-include]
"ATTRIBUTION.md" = "ATTRIBUTION.md"


# Environment setup
[tool.hatch.envs.dev-env]
description = "Environment for development. Includes a DuckDB-backed client."
run = "run-coverage --no-cov"

features = [
  "dev-packages",
  "sql-client-packages",
  "dbt-duckdb",
]

[tool.hatch.envs.dev-env.env-vars]
MF_TEST_ADAPTER_TYPE="duckdb"
MF_SQL_ENGINE_URL="duckdb://"
# This allows us to use the classes in the `dbt-metricflow` package for tests without installing the package.
# `dbt-metricflow` can't be installed as it has `metricflow` as a dependency.
PYTHONPATH="metricflow-semantics:dbt-metricflow"


[tool.hatch.envs.postgres-env.env-vars]
PYTHONPATH="metricflow-semantics:dbt-metricflow"
MF_SQL_ENGINE_URL="postgresql://metricflow@localhost:5432/metricflow"
MF_SQL_ENGINE_PASSWORD="metricflowing"
MF_TEST_ADAPTER_TYPE="postgres"

[tool.hatch.envs.postgres-env]
description = "Dev environment for working with Postgres adapter"

features = [
  "dev-packages",
  "sql-client-packages",
  "dbt-postgres",
]


# NOTE: All of the below should have their authentication credentials
# configured independently of the hatch env construction

[tool.hatch.envs.bigquery-env.env-vars]
PYTHONPATH="metricflow-semantics:dbt-metricflow"
MF_TEST_ADAPTER_TYPE="bigquery"

[tool.hatch.envs.bigquery-env]
description = "Dev environment for working with the BigQuery adapter"

features = [
  "dev-packages",
  "sql-client-packages",
  "dbt-bigquery",
]


[tool.hatch.envs.databricks-env.env-vars]
PYTHONPATH="metricflow-semantics:dbt-metricflow"
MF_TEST_ADAPTER_TYPE="databricks"


[tool.hatch.envs.databricks-env]
description = "Dev environment for working with the Databricks adapter"

features = [
  "dev-packages",
  "sql-client-packages",
  "dbt-databricks",
]


[tool.hatch.envs.redshift-env.env-vars]
PYTHONPATH="metricflow-semantics:dbt-metricflow"
MF_TEST_ADAPTER_TYPE="redshift"

[tool.hatch.envs.redshift-env]
description = "Dev environment for working with the Redshift adapter"

features = [
  "dev-packages",
  "sql-client-packages",
  "dbt-redshift"
]


[tool.hatch.envs.snowflake-env.env-vars]
PYTHONPATH="metricflow-semantics:dbt-metricflow"
MF_TEST_ADAPTER_TYPE="snowflake"

[tool.hatch.envs.snowflake-env]
description = "Dev environment for working with Snowflake adapter"

features = [
  "dev-packages",
  "sql-client-packages",
  "dbt-snowflake",
]


[tool.hatch.envs.trino-env.env-vars]
PYTHONPATH="metricflow-semantics:dbt-metricflow"
MF_TEST_ADAPTER_TYPE = "trino"
MF_SQL_ENGINE_URL = "trino://trino@localhost:8080/"
DBT_ENV_SECRET_CATALOG="memory"

[tool.hatch.envs.trino-env]
description = "Dev environment for working with the Trino adapter"

features = [
  "dev-packages",
  "sql-client-packages",
  "trino-sql-client-packages",
  "dbt-trino"
]


[tool.black]
line-length = 120

[tool.pytest.ini_options]
# Many deprecation warnings come from 3rd-party libraries and make the
# output of pytest noisy. Since no action is going to be taken, hide those
# warnings.
filterwarnings = [
  "ignore:Deprecated call to.*",
  "ignore:pkg_resources is deprecated as an API"
]
python_functions = "test_* populate_source_schema"
