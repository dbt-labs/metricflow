from __future__ import annotations

import logging
import sys
from contextlib import contextmanager, redirect_stderr, redirect_stdout
from enum import Enum
from functools import cached_property
from pathlib import Path
from typing import Iterator, Optional, TextIO

from dbt_semantic_interfaces.test_utils import as_datetime
from metricflow_semantics.errors.error_classes import (
    UnsupportedEngineFeatureError,
)
from metricflow_semantics.model.semantic_manifest_lookup import SemanticManifestLookup
from metricflow_semantics.query.query_parser import MetricFlowQueryParser
from metricflow_semantics.specs.dunder_column_association_resolver import DunderColumnAssociationResolver
from metricflow_semantics.test_helpers.time_helpers import ConfigurableTimeSource
from metricflow_semantics.toolkit.cache.result_cache import ResultCache
from metricflow_semantics.toolkit.collections.ordered_set import FrozenOrderedSet
from metricflow_semantics.toolkit.dataclass_helpers import fast_frozen_dataclass
from metricflow_semantics.toolkit.mf_logging.lazy_formattable import LazyFormat
from metricflow_semantics.toolkit.mf_logging.pretty_formattable import MetricFlowPrettyFormattable
from metricflow_semantics.toolkit.mf_logging.pretty_formatter import PrettyFormatContext
from metricflow_semantics.toolkit.performance_helpers import ExecutionTimer
from metricflow_semantics.toolkit.time_helpers import PrettyDuration
from typing_extensions import override

from metricflow.engine.metricflow_engine import MetricFlowEngine, MetricFlowQueryRequest
from tests_metricflow.fixtures.sql_client_fixtures import make_test_sql_client
from tests_metricflow.fixtures.sql_clients.ddl_sql_client import SqlClientWithDDLMethods
from tests_metricflow.release_validation.manifest_setup.manifest_setup import ManifestSetup
from tests_metricflow.table_snapshot.table_snapshots import SqlTableSnapshotLoader

logger = logging.getLogger(__name__)


class ExplainQueryStatus(Enum):
    """Describes the status of the `explain` call."""

    # SQL was generated and explained without error.s
    PASS = "pass"
    # Request was not supported by the MF engine.
    MF_UNSUPPORTED = "mf_unsupported"
    # Request raised an exception in the MF engine.
    MF_EXCEPTION = "mf_exception"
    # Generated SQL raised an exception when explained by the SQL engine.
    SQL_EXCEPTION = "sql_exception"


@fast_frozen_dataclass()
class ResultFilePathSet:
    """Groups paths used to store results of running the MF engine request.

    Separate files make it easier to browse results in the filesystem, but a consolidated approach might be better.
    """

    log_file_path: Path
    # Contains SQL generated by the `explain` call.
    explain_sql_file_path: Path
    # Contains the exception string if the `explain` call could not be completed because it's not supported in the
    # current configuration.
    mf_unsupported_file_path: Path
    # Contains the exception string if the `explain` call failed for any other reason.
    mf_exception_file_path: Path
    # Contains the exception string from the SQL engine if the generated SQL could not be explained.
    sql_exception_file_path: Path

    @staticmethod
    def create(path_prefix: Path) -> ResultFilePathSet:  # noqa: D102
        return ResultFilePathSet(
            log_file_path=path_prefix.with_name(path_prefix.name + ".log"),
            explain_sql_file_path=path_prefix.with_name(path_prefix.name + "_explain_sql.txt"),
            mf_unsupported_file_path=path_prefix.with_name(path_prefix.name + "mf_unsupported.txt"),
            mf_exception_file_path=path_prefix.with_name(path_prefix.name + "_mf_exception.txt"),
            sql_exception_file_path=path_prefix.with_name(path_prefix.name + "_sql_exception.txt"),
        )


@fast_frozen_dataclass()
class ExplainTaskResult:
    """Result object passed from the worker process to the main process.

    Since this object is pickled and stored in the main process, it should be lightweight to conserve memory.
    """

    manifest_name: str
    request_name: str
    mf_request: MetricFlowQueryRequest
    status: ExplainQueryStatus
    execution_duration: PrettyDuration
    result_file_path_set: ResultFilePathSet


@fast_frozen_dataclass()
class MetricFlowExplainTask(MetricFlowPrettyFormattable):
    """Describes the task that should be run by the `DuckDbExplainTaskRunner`."""

    # The manifest setup to use for running the request.
    manifest_setup: ManifestSetup
    # The name of the request for logging purposes.
    request_name: str
    # The request to pass to the MF engine.
    mf_request: MetricFlowQueryRequest
    # The prefix of the path to use to generate the result files. See `ResultFilePathSet`.
    result_file_prefix: Path

    @cached_property
    def manifest_name(self) -> str:  # noqa: D102
        return self.manifest_setup.manifest_name

    @override
    def pretty_format(self, format_context: PrettyFormatContext) -> Optional[str]:
        return format_context.formatter.pretty_format_object_by_parts(
            class_name=self.__class__.__name__,
            field_mapping={
                "manifest_name": self.manifest_setup.manifest_name,
                "request_name": self.request_name,
                "mf_request": self.mf_request,
                "result_file_prefix": self.result_file_prefix,
                # Avoid including the entire manifest.
            },
        )


class DuckDbExplainTaskRunner:
    """Runs an explain task.

    This is intended to be called from a worker process in a `ProcessPoolExecutor`. Since a worker only runs one task
    at a time, class variables are used to store state.
    """

    _manifest_name_to_mf_engine: ResultCache[str, MetricFlowEngine] = ResultCache()
    _sql_client_cache: ResultCache[None, SqlClientWithDDLMethods] = ResultCache()

    @classmethod
    def _get_sql_client(cls) -> SqlClientWithDDLMethods:
        result = cls._sql_client_cache.get(None)
        if result:
            return result.value

        return cls._sql_client_cache.set_and_get(
            None, make_test_sql_client(url="duckdb://", password="", schema="default_schema")
        )

    @classmethod
    def _get_engine(
        cls,
        explain_task: MetricFlowExplainTask,
    ) -> MetricFlowEngine:
        result = cls._manifest_name_to_mf_engine.get(explain_task.manifest_name)
        if result:
            return result.value

        sql_client = cls._get_sql_client()
        schema_names = FrozenOrderedSet(
            table_snapshot.schema_name
            for table_snapshot in explain_task.manifest_setup.table_snapshots
            if table_snapshot.schema_name is not None
        )
        for schema_name in schema_names:
            query = f"CREATE SCHEMA IF NOT EXISTS {schema_name}"
            sql_client.execute(query)

        table_snapshot_loader = SqlTableSnapshotLoader(ddl_sql_client=sql_client)
        for table_snapshot in explain_task.manifest_setup.table_snapshots:
            try:
                table_snapshot_loader.load(table_snapshot)
            except Exception as e:
                raise RuntimeError(LazyFormat("Error loading table snapshot", table_snapshot=table_snapshot)) from e
        logger.info(
            LazyFormat(
                "Loaded tables",
                table_names=[
                    table_snapshot.table_name for table_snapshot in explain_task.manifest_setup.table_snapshots
                ],
            )
        )

        column_association_resolver = DunderColumnAssociationResolver()
        semantic_manifest_lookup = SemanticManifestLookup(explain_task.manifest_setup.semantic_manifest)
        query_parser = MetricFlowQueryParser(semantic_manifest_lookup=semantic_manifest_lookup)
        mf_engine = MetricFlowEngine(
            semantic_manifest_lookup=semantic_manifest_lookup,
            sql_client=sql_client,
            time_source=ConfigurableTimeSource(as_datetime("2020-01-01")),
            query_parser=query_parser,
            column_association_resolver=column_association_resolver,
        )

        return cls._manifest_name_to_mf_engine.set_and_get(key=explain_task.manifest_name, value=mf_engine)

    @classmethod
    def run_task(cls, explain_task: MetricFlowExplainTask) -> ExplainTaskResult:
        """Run the given task and return the result.

        The result of running the task are written to files as described in the result object.
        """
        with ExecutionTimer() as timer:
            result_file_path_set = ResultFilePathSet.create(explain_task.result_file_prefix)
            status = cls._run_task(
                explain_task=explain_task,
                result_file_path_set=result_file_path_set,
            )

        return ExplainTaskResult(
            manifest_name=explain_task.manifest_name,
            request_name=explain_task.request_name,
            mf_request=explain_task.mf_request,
            status=status,
            execution_duration=timer.total_duration,
            result_file_path_set=result_file_path_set,
        )

    @classmethod
    def _run_task(
        cls,
        explain_task: MetricFlowExplainTask,
        result_file_path_set: ResultFilePathSet,
    ) -> ExplainQueryStatus:
        with cls._redirect_output_to_file(result_file_path_set.log_file_path):
            logger.info(LazyFormat("Running task", explain_task=explain_task))
            try:
                mf_engine = cls._get_engine(explain_task)
                result = mf_engine.explain(explain_task.mf_request)
                sql = result.sql_statement.sql
                with open(result_file_path_set.explain_sql_file_path, "w") as fp:
                    fp.write(sql)
            except UnsupportedEngineFeatureError as e:
                logger.exception(
                    LazyFormat(
                        "Unsupported feature",
                        manifest_name=explain_task.manifest_name,
                        query_task=explain_task,
                    )
                )
                with open(result_file_path_set.mf_unsupported_file_path, "w") as fp:
                    fp.write(str(e))
                return ExplainQueryStatus.MF_UNSUPPORTED
            except Exception as e:
                logger.exception(
                    LazyFormat(
                        "Error running MF EXPLAIN",
                        manifest_name=explain_task.manifest_name,
                        query_task=explain_task,
                    )
                )
                with open(result_file_path_set.mf_exception_file_path, "w") as fp:
                    fp.write(str(e))
                return ExplainQueryStatus.MF_EXCEPTION

            try:
                sql_client = cls._get_sql_client()
                sql_client.dry_run(sql)
            except Exception as e:
                logger.exception(
                    LazyFormat(
                        "Error running EXPLAIN SQL",
                        manifest_name=explain_task.manifest_name,
                        query_task=explain_task,
                    )
                )
                with open(result_file_path_set.sql_exception_file_path, "w") as fp:
                    fp.write(str(e))
                return ExplainQueryStatus.SQL_EXCEPTION

            return ExplainQueryStatus.PASS

    @classmethod
    @contextmanager
    def _redirect_output_to_file(cls, log_file_path: Path) -> Iterator[TextIO]:
        """Provides a context manager to redirect output, stderr, and logging output to the given file.

        Useful for debugging as without the log file, the output is invisible. This method is not thread safe due to
        mutation of global state (i.e. logging configuration, `redirect_*`).
        """
        log_file_path.parent.mkdir(parents=True, exist_ok=True)

        with open(log_file_path, "w") as log_file:
            with (
                redirect_stdout(log_file),
                redirect_stderr(log_file),
            ):
                # Setup logging. Note: a new process does not inherit the logging configuration of the parent process.
                logging_handler = logging.StreamHandler(log_file)
                logging_handler.setFormatter(
                    logging.Formatter(
                        "%(asctime)s %(levelname)s %(filename)s:%(lineno)d [%(threadName)s] - %(message)s"
                    )
                )
                root_logger = logging.getLogger()
                previous_level = root_logger.getEffectiveLevel()
                try:
                    root_logger.setLevel(logging.INFO)
                    root_logger.addHandler(logging_handler)
                    yield log_file
                finally:
                    root_logger.removeHandler(logging_handler)
                    root_logger.setLevel(previous_level)
                    sys.stdout.flush()
                    sys.stderr.flush()
                    log_file.flush()
